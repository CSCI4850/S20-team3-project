{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the heat of the moment, when the enemy missiles are bearing down, a human being will utilize their learned abilities to react, and come out on top. Action games are a perfect environment for this learned ability to react to shine, and have been shown to improve players' perception, attention, and reaction time.[^1] We believe that by recreating the scenarios in which the human brain reacts, we can uncover how it learns to react. To do this, we will be using a Deep Q-Learning Network with Reinforcement Learning techniques to learn to play the 1981 Arcade Classic: Galaga.\n",
    "\n",
    "Utilizing the OpenAI Gym, and its Retro Gym environment additions, the network will learn to identify gameplay elements using convolutional layers, learn actions through reward, and establish a state-decision formula using Q-Learning. Our techniques may vary as development continues.\n",
    "\n",
    "Our network will be built using the tools provided by the Tensorflow and Tensorflow Keras python libraries. Our input data will be provided by the OpenAI Retro Gym, and includes full per-pixel data of the screen after an action is taken. Some of these observations are provided by the default Galaga environment, but we have the ability to add more observations as we find necessary. Our output data will consist of a vector mapping to one of three actions in the Action Space, a one dimensional vector of Galaga's actions: Move Left, Move Right, Fire. The OpenAI Retro Gym allows us a viewless, increased speed version of the game that can speed up training times.\n",
    "\n",
    "To support our DQN Agent, we will utilize a first-phase Deep Convolutional network to process the by-pixel observation and produce inputs for our second-phase DQN Agent that will determine which action to take.\n",
    "\n",
    "We intend to separate Galaga's 255 available levels into three interleaving sets for training, validation, and testing. Using a mix of difficult, simple, and special levels among the sets to ensure training, validation, and testing requirements are met, while also ensuring the Network has a proper variety of training data as to be able to meet any Galaga level.\n",
    "\n",
    "Galaga is a simple, straight-forward game. Its action space is small, and enemy actions are telegraphed. This makes Galaga simple to learn, but through its method of increasing enemy counts and firing rates, as well as introducing special enemies at points, Galaga is also a hard game to master.\n",
    "\n",
    "Our input data, delivered from OpenAI Gym as observations from the frame after an action is made, will include the following:\n",
    "- Ship Position\n",
    "- Ship Missile Position\n",
    "- Enemy Positions\n",
    "- Enemy Missile Positions\n",
    "\n",
    "Further required input data will be determined as development continues.\n",
    "\n",
    "Each fit of the model would cover one playthrough of the game, beginning at the first level of the training set and continuing until the unit is out of lives or has completed the final level of the training set.\n",
    "\n",
    "Evaluation of the model would cover one playthrough of the game, beginning at the first level of the testing set and continuing until the unit is out of lives or has completed the final level of the testing set.\n",
    "\n",
    "Comparative evaluation assessment would be done utilizing:\n",
    "- Past high scores\n",
    "- Global high score list (human players)\n",
    "- Global high score list (other neural networks) !(In whatever quantity these are found available\n",
    "- Etcetera Galaga stats about performance\n",
    "    \n",
    "References:\n",
    "1. Nauert, R. (2018, August 8). Action Video Games May Improve Cognitive Skills. Retrieved February 13, 2020, from https://psychcentral.com/news/2017/12/13/action-video-games-may-improve-cognitive-skills/129902.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
